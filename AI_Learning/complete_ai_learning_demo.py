"""
AIå­¦ä¹ å®Œæ•´æ¼”ç¤º
åŒ…å«æ‰€æœ‰æ¨¡å—çš„æ ¸å¿ƒæ¦‚å¿µå’Œä»£ç ç¤ºä¾‹
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import make_classification, make_regression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.metrics import accuracy_score, mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')

import matplotlib
matplotlib.rcParams['font.sans-serif'] = ['SimHei']

class CompleteAILearningDemo:
    """AIå­¦ä¹ å®Œæ•´æ¼”ç¤ºç±»"""
    
    def __init__(self):
        print("ğŸ“ AIå­¦ä¹ å®Œæ•´æ¼”ç¤º")
        print("=" * 60)
        print("è¿™ä¸ªæ¼”ç¤ºåŒ…å«äº†AIå­¦ä¹ çš„æ‰€æœ‰æ ¸å¿ƒæ¦‚å¿µ")
        print("åŒ…æ‹¬ï¼šPythonåŸºç¡€ã€æ•°å­¦åŸºç¡€ã€æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€é¡¹ç›®å®æˆ˜")
        print("=" * 60)
    
    def python_fundamentals_demo(self):
        """PythonåŸºç¡€æ¼”ç¤º"""
        print("\nğŸ PythonåŸºç¡€å¼ºåŒ–æ¼”ç¤º")
        print("=" * 50)
        
        # 1. è£…é¥°å™¨ç¤ºä¾‹
        def timer(func):
            import time
            def wrapper(*args, **kwargs):
                start = time.time()
                result = func(*args, **kwargs)
                end = time.time()
                print(f"å‡½æ•° {func.__name__} æ‰§è¡Œæ—¶é—´: {end-start:.4f}ç§’")
                return result
            return wrapper
        
        @timer
        def fibonacci(n):
            if n <= 1:
                return n
            return fibonacci(n-1) + fibonacci(n-2)
        
        print("1. è£…é¥°å™¨ç¤ºä¾‹ - è®¡æ—¶å™¨:")
        result = fibonacci(10)
        print(f"fibonacci(10) = {result}")
        
        # 2. ç”Ÿæˆå™¨ç¤ºä¾‹
        def number_generator(n):
            for i in range(n):
                yield i ** 2
        
        print(f"\n2. ç”Ÿæˆå™¨ç¤ºä¾‹:")
        squares = list(number_generator(5))
        print(f"å‰5ä¸ªå¹³æ–¹æ•°: {squares}")
        
        # 3. NumPyåŸºç¡€
        print(f"\n3. NumPyåŸºç¡€æ“ä½œ:")
        arr = np.array([[1, 2, 3], [4, 5, 6]])
        print(f"æ•°ç»„:\n{arr}")
        print(f"å½¢çŠ¶: {arr.shape}")
        print(f"è½¬ç½®:\n{arr.T}")
        print(f"ç»Ÿè®¡: å‡å€¼={np.mean(arr):.2f}, æ ‡å‡†å·®={np.std(arr):.2f}")
        
        # 4. PandasåŸºç¡€
        print(f"\n4. PandasåŸºç¡€æ“ä½œ:")
        data = {
            'name': ['Alice', 'Bob', 'Charlie'],
            'age': [25, 30, 35],
            'score': [85, 92, 78]
        }
        df = pd.DataFrame(data)
        print(f"DataFrame:\n{df}")
        print(f"å¹´é¾„å¤§äº25çš„è®°å½•:\n{df[df['age'] > 25]}")
        
        print("âœ… PythonåŸºç¡€æ¼”ç¤ºå®Œæˆ")
    
    def math_foundations_demo(self):
        """æ•°å­¦åŸºç¡€æ¼”ç¤º"""
        print("\nğŸ“ æ•°å­¦åŸºç¡€æ¼”ç¤º")
        print("=" * 50)
        
        # 1. çº¿æ€§ä»£æ•°
        print("1. çº¿æ€§ä»£æ•°åŸºç¡€:")
        A = np.array([[1, 2], [3, 4]])
        B = np.array([[5, 6], [7, 8]])
        
        print(f"çŸ©é˜µA:\n{A}")
        print(f"çŸ©é˜µB:\n{B}")
        print(f"çŸ©é˜µä¹˜æ³• A@B:\n{A @ B}")
        
        # ç‰¹å¾å€¼åˆ†è§£
        eigenvals, eigenvecs = np.linalg.eig(A)
        print(f"Açš„ç‰¹å¾å€¼: {eigenvals}")
        print(f"Açš„ç‰¹å¾å‘é‡:\n{eigenvecs}")
        
        # 2. æ¦‚ç‡ç»Ÿè®¡
        print(f"\n2. æ¦‚ç‡ç»Ÿè®¡åŸºç¡€:")
        # ç”Ÿæˆæ­£æ€åˆ†å¸ƒæ•°æ®
        data = np.random.normal(100, 15, 1000)
        print(f"æ­£æ€åˆ†å¸ƒæ•°æ®ç»Ÿè®¡:")
        print(f"å‡å€¼: {np.mean(data):.2f}")
        print(f"æ ‡å‡†å·®: {np.std(data):.2f}")
        print(f"95%ç½®ä¿¡åŒºé—´: [{np.percentile(data, 2.5):.2f}, {np.percentile(data, 97.5):.2f}]")
        
        # 3. å¯è§†åŒ–æ•°å­¦æ¦‚å¿µ
        plt.figure(figsize=(12, 4))
        
        # ç‰¹å¾å‘é‡å¯è§†åŒ–
        plt.subplot(1, 3, 1)
        origin = [0, 0]
        plt.quiver(*origin, eigenvecs[0, 0], eigenvecs[1, 0], scale=1, scale_units='xy', angles='xy', color='red', label='ç‰¹å¾å‘é‡1')
        plt.quiver(*origin, eigenvecs[0, 1], eigenvecs[1, 1], scale=1, scale_units='xy', angles='xy', color='blue', label='ç‰¹å¾å‘é‡2')
        plt.xlim(-1, 1)
        plt.ylim(-1, 1)
        plt.grid(True)
        plt.legend()
        plt.title('ç‰¹å¾å‘é‡å¯è§†åŒ–')
        
        # æ­£æ€åˆ†å¸ƒ
        plt.subplot(1, 3, 2)
        plt.hist(data, bins=30, density=True, alpha=0.7, color='skyblue')
        x = np.linspace(data.min(), data.max(), 100)
        y = (1/np.sqrt(2*np.pi*15**2)) * np.exp(-0.5*((x-100)/15)**2)
        plt.plot(x, y, 'r-', linewidth=2, label='ç†è®ºæ­£æ€åˆ†å¸ƒ')
        plt.title('æ­£æ€åˆ†å¸ƒ')
        plt.legend()
        
        # å‡½æ•°å›¾åƒ
        plt.subplot(1, 3, 3)
        x = np.linspace(-5, 5, 100)
        sigmoid = 1 / (1 + np.exp(-x))
        plt.plot(x, sigmoid, label='Sigmoid')
        plt.plot(x, np.maximum(0, x), label='ReLU')
        plt.title('æ¿€æ´»å‡½æ•°')
        plt.legend()
        plt.grid(True)
        
        plt.tight_layout()
        plt.show()
        
        print("âœ… æ•°å­¦åŸºç¡€æ¼”ç¤ºå®Œæˆ")
    
    def machine_learning_demo(self):
        """æœºå™¨å­¦ä¹ æ¼”ç¤º"""
        print("\nğŸ¤– æœºå™¨å­¦ä¹ æ¼”ç¤º")
        print("=" * 50)
        
        # 1. ç›‘ç£å­¦ä¹  - å›å½’
        print("1. çº¿æ€§å›å½’æ¼”ç¤º:")
        X_reg, y_reg = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)
        X_train, X_test, y_train, y_test = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)
        
        lr = LinearRegression()
        lr.fit(X_train, y_train)
        y_pred = lr.predict(X_test)
        
        r2 = r2_score(y_test, y_pred)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        
        print(f"RÂ²å¾—åˆ†: {r2:.4f}")
        print(f"RMSE: {rmse:.2f}")
        
        # 2. ç›‘ç£å­¦ä¹  - åˆ†ç±»
        print(f"\n2. é€»è¾‘å›å½’æ¼”ç¤º:")
        X_clf, y_clf = make_classification(n_samples=1000, n_features=2, n_redundant=0, 
                                         n_informative=2, n_clusters_per_class=1, random_state=42)
        X_train, X_test, y_train, y_test = train_test_split(X_clf, y_clf, test_size=0.2, random_state=42)
        
        # æ ‡å‡†åŒ–
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        log_reg = LogisticRegression()
        log_reg.fit(X_train_scaled, y_train)
        y_pred_clf = log_reg.predict(X_test_scaled)
        
        accuracy = accuracy_score(y_test, y_pred_clf)
        print(f"åˆ†ç±»å‡†ç¡®ç‡: {accuracy:.4f}")
        
        # 3. æ— ç›‘ç£å­¦ä¹  - èšç±»
        print(f"\n3. K-meansèšç±»æ¼”ç¤º:")
        kmeans = KMeans(n_clusters=2, random_state=42)
        clusters = kmeans.fit_predict(X_clf)
        
        print(f"èšç±»ä¸­å¿ƒ:\n{kmeans.cluster_centers_}")
        
        # 4. é™ç»´
        print(f"\n4. PCAé™ç»´æ¼”ç¤º:")
        pca = PCA(n_components=2)
        X_pca = pca.fit_transform(X_clf)
        
        print(f"ä¸»æˆåˆ†æ–¹å·®è§£é‡Šæ¯”ä¾‹: {pca.explained_variance_ratio_}")
        print(f"ç´¯è®¡æ–¹å·®è§£é‡Šæ¯”ä¾‹: {np.sum(pca.explained_variance_ratio_):.4f}")
        
        # å¯è§†åŒ–æœºå™¨å­¦ä¹ ç»“æœ
        plt.figure(figsize=(15, 5))
        
        # å›å½’ç»“æœ
        plt.subplot(1, 3, 1)
        plt.scatter(X_test, y_test, alpha=0.6, label='çœŸå®å€¼')
        plt.scatter(X_test, y_pred, alpha=0.6, label='é¢„æµ‹å€¼')
        plt.title(f'çº¿æ€§å›å½’ (RÂ²={r2:.3f})')
        plt.legend()
        
        # åˆ†ç±»ç»“æœ
        plt.subplot(1, 3, 2)
        plt.scatter(X_test_scaled[:, 0], X_test_scaled[:, 1], c=y_test, cmap='viridis', alpha=0.6)
        plt.title(f'é€»è¾‘å›å½’åˆ†ç±» (å‡†ç¡®ç‡={accuracy:.3f})')
        
        # èšç±»ç»“æœ
        plt.subplot(1, 3, 3)
        plt.scatter(X_clf[:, 0], X_clf[:, 1], c=clusters, cmap='viridis', alpha=0.6)
        plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], 
                   c='red', marker='x', s=200, linewidths=3, label='èšç±»ä¸­å¿ƒ')
        plt.title('K-meansèšç±»')
        plt.legend()
        
        plt.tight_layout()
        plt.show()
        
        print("âœ… æœºå™¨å­¦ä¹ æ¼”ç¤ºå®Œæˆ")
    
    def deep_learning_demo(self):
        """æ·±åº¦å­¦ä¹ åŸºç¡€æ¼”ç¤º"""
        print("\nğŸ§  æ·±åº¦å­¦ä¹ åŸºç¡€æ¼”ç¤º")
        print("=" * 50)
        
        # 1. æ¿€æ´»å‡½æ•°
        print("1. æ¿€æ´»å‡½æ•°æ¼”ç¤º:")
        x = np.linspace(-5, 5, 100)
        
        def sigmoid(x):
            return 1 / (1 + np.exp(-np.clip(x, -500, 500)))
        
        def relu(x):
            return np.maximum(0, x)
        
        def tanh(x):
            return np.tanh(x)
        
        plt.figure(figsize=(12, 4))
        
        plt.subplot(1, 3, 1)
        plt.plot(x, sigmoid(x), label='Sigmoid', linewidth=2)
        plt.title('Sigmoidæ¿€æ´»å‡½æ•°')
        plt.grid(True)
        plt.legend()
        
        plt.subplot(1, 3, 2)
        plt.plot(x, relu(x), label='ReLU', linewidth=2, color='red')
        plt.title('ReLUæ¿€æ´»å‡½æ•°')
        plt.grid(True)
        plt.legend()
        
        plt.subplot(1, 3, 3)
        plt.plot(x, tanh(x), label='Tanh', linewidth=2, color='green')
        plt.title('Tanhæ¿€æ´»å‡½æ•°')
        plt.grid(True)
        plt.legend()
        
        plt.tight_layout()
        plt.show()
        
        # 2. ç®€å•ç¥ç»ç½‘ç»œæ¦‚å¿µ
        print(f"\n2. ç¥ç»ç½‘ç»œæ¦‚å¿µ:")
        print("ç¥ç»ç½‘ç»œçš„åŸºæœ¬ç»„æˆ:")
        print("- è¾“å…¥å±‚ï¼šæ¥æ”¶æ•°æ®")
        print("- éšè—å±‚ï¼šç‰¹å¾æå–å’Œå˜æ¢")
        print("- è¾“å‡ºå±‚ï¼šäº§ç”Ÿæœ€ç»ˆç»“æœ")
        print("- æ¿€æ´»å‡½æ•°ï¼šå¼•å…¥éçº¿æ€§")
        print("- æŸå¤±å‡½æ•°ï¼šè¡¡é‡é¢„æµ‹è¯¯å·®")
        print("- ä¼˜åŒ–å™¨ï¼šæ›´æ–°ç½‘ç»œå‚æ•°")
        
        # 3. æ¢¯åº¦ä¸‹é™å¯è§†åŒ–
        print(f"\n3. æ¢¯åº¦ä¸‹é™å¯è§†åŒ–:")
        
        def cost_function(w):
            return (w - 2)**2 + 1
        
        def gradient(w):
            return 2 * (w - 2)
        
        # æ¢¯åº¦ä¸‹é™è¿‡ç¨‹
        w = 0.0
        learning_rate = 0.1
        history = [w]
        
        for _ in range(20):
            grad = gradient(w)
            w = w - learning_rate * grad
            history.append(w)
        
        # å¯è§†åŒ–
        plt.figure(figsize=(10, 5))
        
        plt.subplot(1, 2, 1)
        w_range = np.linspace(-1, 5, 100)
        cost_values = cost_function(w_range)
        plt.plot(w_range, cost_values, 'b-', linewidth=2, label='æŸå¤±å‡½æ•°')
        plt.plot(history, [cost_function(w) for w in history], 'ro-', label='æ¢¯åº¦ä¸‹é™è·¯å¾„')
        plt.xlabel('æƒé‡ w')
        plt.ylabel('æŸå¤±')
        plt.title('æ¢¯åº¦ä¸‹é™ä¼˜åŒ–è¿‡ç¨‹')
        plt.legend()
        plt.grid(True)
        
        plt.subplot(1, 2, 2)
        plt.plot(history, 'go-', linewidth=2)
        plt.xlabel('è¿­ä»£æ¬¡æ•°')
        plt.ylabel('æƒé‡å€¼')
        plt.title('æƒé‡æ”¶æ•›è¿‡ç¨‹')
        plt.grid(True)
        
        plt.tight_layout()
        plt.show()
        
        print(f"æœ€ç»ˆæƒé‡: {history[-1]:.4f} (ç›®æ ‡: 2.0)")
        print("âœ… æ·±åº¦å­¦ä¹ åŸºç¡€æ¼”ç¤ºå®Œæˆ")
    
    def project_demo(self):
        """é¡¹ç›®å®æˆ˜æ¼”ç¤º"""
        print("\nğŸ  é¡¹ç›®å®æˆ˜æ¼”ç¤º - ç®€åŒ–ç‰ˆæˆ¿ä»·é¢„æµ‹")
        print("=" * 50)
        
        # 1. ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        np.random.seed(42)
        n_samples = 500
        
        # ç‰¹å¾ï¼šé¢ç§¯ã€æˆ¿é—´æ•°ã€å¹´é¾„
        area = np.random.normal(100, 30, n_samples)
        rooms = np.random.randint(1, 6, n_samples)
        age = np.random.randint(0, 30, n_samples)
        
        # ç›®æ ‡ï¼šä»·æ ¼ï¼ˆåŸºäºç‰¹å¾çš„çº¿æ€§ç»„åˆåŠ å™ªå£°ï¼‰
        price = (area * 50 + rooms * 10000 - age * 500 + 
                np.random.normal(0, 5000, n_samples))
        price = np.maximum(price, 10000)  # ç¡®ä¿ä»·æ ¼ä¸ºæ­£
        
        # åˆ›å»ºDataFrame
        data = pd.DataFrame({
            'area': area,
            'rooms': rooms,
            'age': age,
            'price': price
        })
        
        print("1. æ•°æ®æ¢ç´¢:")
        print(data.describe())
        
        # 2. ç‰¹å¾å·¥ç¨‹
        data['price_per_sqm'] = data['price'] / data['area']
        data['is_new'] = (data['age'] < 5).astype(int)
        
        print(f"\n2. ç‰¹å¾å·¥ç¨‹å®Œæˆï¼Œæ–°å¢ç‰¹å¾:")
        print("- price_per_sqm: æ¯å¹³ç±³ä»·æ ¼")
        print("- is_new: æ˜¯å¦ä¸ºæ–°æˆ¿")
        
        # 3. æ¨¡å‹è®­ç»ƒ
        features = ['area', 'rooms', 'age', 'is_new']
        X = data[features]
        y = data['price']
        
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # è®­ç»ƒå¤šä¸ªæ¨¡å‹
        models = {
            'Linear Regression': LinearRegression(),
            'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42)
        }
        
        results = {}
        
        print(f"\n3. æ¨¡å‹è®­ç»ƒç»“æœ:")
        for name, model in models.items():
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
            
            r2 = r2_score(y_test, y_pred)
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            
            results[name] = {'r2': r2, 'rmse': rmse, 'predictions': y_pred}
            print(f"{name}: RÂ²={r2:.4f}, RMSE={rmse:.0f}")
        
        # 4. ç»“æœå¯è§†åŒ–
        plt.figure(figsize=(15, 5))
        
        # æ•°æ®åˆ†å¸ƒ
        plt.subplot(1, 3, 1)
        plt.hist(data['price'], bins=30, alpha=0.7, edgecolor='black')
        plt.title('æˆ¿ä»·åˆ†å¸ƒ')
        plt.xlabel('ä»·æ ¼')
        plt.ylabel('é¢‘æ•°')
        
        # é¢ç§¯vsä»·æ ¼
        plt.subplot(1, 3, 2)
        plt.scatter(data['area'], data['price'], alpha=0.6)
        plt.xlabel('é¢ç§¯')
        plt.ylabel('ä»·æ ¼')
        plt.title('é¢ç§¯vsä»·æ ¼å…³ç³»')
        
        # é¢„æµ‹vsçœŸå®
        plt.subplot(1, 3, 3)
        best_model = max(results.keys(), key=lambda k: results[k]['r2'])
        best_pred = results[best_model]['predictions']
        
        plt.scatter(y_test, best_pred, alpha=0.6)
        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
        plt.xlabel('çœŸå®ä»·æ ¼')
        plt.ylabel('é¢„æµ‹ä»·æ ¼')
        plt.title(f'{best_model} - é¢„æµ‹vsçœŸå®')
        
        plt.tight_layout()
        plt.show()
        
        print(f"\n4. é¡¹ç›®æ€»ç»“:")
        print(f"æœ€ä½³æ¨¡å‹: {best_model}")
        print(f"æ¨¡å‹æ€§èƒ½: RÂ²={results[best_model]['r2']:.4f}")
        print("âœ… é¡¹ç›®å®æˆ˜æ¼”ç¤ºå®Œæˆ")
    
    def run_complete_demo(self):
        """è¿è¡Œå®Œæ•´æ¼”ç¤º"""
        self.python_fundamentals_demo()
        self.math_foundations_demo()
        self.machine_learning_demo()
        self.deep_learning_demo()
        self.project_demo()
        
        print(f"\nğŸ‰ AIå­¦ä¹ å®Œæ•´æ¼”ç¤ºç»“æŸï¼")
        print(f"\nğŸ“š å­¦ä¹ è·¯å¾„æ€»ç»“:")
        print("1. âœ… PythonåŸºç¡€å¼ºåŒ– - æŒæ¡é«˜çº§ç‰¹æ€§å’Œæ•°æ®å¤„ç†")
        print("2. âœ… æ•°å­¦åŸºç¡€å¤ä¹  - çº¿æ€§ä»£æ•°å’Œæ¦‚ç‡ç»Ÿè®¡")
        print("3. âœ… æœºå™¨å­¦ä¹ åŸºç¡€ - ç›‘ç£å­¦ä¹ å’Œæ— ç›‘ç£å­¦ä¹ ")
        print("4. âœ… æ·±åº¦å­¦ä¹ å…¥é—¨ - ç¥ç»ç½‘ç»œåŸºæœ¬æ¦‚å¿µ")
        print("5. âœ… é¡¹ç›®å®æˆ˜ç»ƒä¹  - å®Œæ•´çš„æœºå™¨å­¦ä¹ é¡¹ç›®")
        
        print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥å­¦ä¹ å»ºè®®:")
        print("1. æ·±å…¥å­¦ä¹ æ¯ä¸ªæ¨¡å—çš„è¯¦ç»†å†…å®¹")
        print("2. å®Œæˆæ›´å¤šå®é™…é¡¹ç›®ç»ƒä¹ ")
        print("3. å­¦ä¹ æ·±åº¦å­¦ä¹ æ¡†æ¶ (PyTorch/TensorFlow)")
        print("4. å‚ä¸å¼€æºé¡¹ç›®å’Œç«èµ›")
        print("5. æŒç»­å…³æ³¨AIé¢†åŸŸæœ€æ–°å‘å±•")

def main():
    """ä¸»å‡½æ•°"""
    demo = CompleteAILearningDemo()
    demo.run_complete_demo()

if __name__ == "__main__":
    main()
